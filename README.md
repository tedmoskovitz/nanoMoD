
# nanoMoD

![nanoGPT](assets/nanogpt.jpg)

This is a super minimal implementation of [Mixture-of-Depths](https://arxiv.org/abs/2404.02258) (MoD) on top of Andrej Karpathy's amazing nanoGPT [repository](https://github.com/karpathy/nanoGPT). 

All usage and script invocations are identical to the original codebase.

I've only tried out small-scale experiments on the Shakespeare corpus, but results seem consistent with those reported in the MoD paper. A major TODO right now is to implement autoregressive sampling. Have fun! 